{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a linear model and deep neural net from scratch\n",
    "## Titanic Kaggle Competition\n",
    "\n",
    "### Setting up the environment and downloading data\n",
    "Setting up environement and kaggle API either for google colab or local machine, and downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming running in local environment...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "  colab_flag = True\n",
    "else:\n",
    "  colab_flag = False\n",
    "\n",
    "if colab_flag == True:\n",
    "   print(\"Running in Colab...\")\n",
    "   #Install Kaggle API\n",
    "   ! pip install -q kaggle\n",
    "   #Install Huggingface Datasets lib\n",
    "   ! pip install -q datasets\n",
    "   #Install Huggingface transformers & the sentencepiece\n",
    "   ! pip install -q transformers[sentencepiece,torch]\n",
    "   print(\"...Installed required dependencies\")\n",
    "else:\n",
    "   print(\"Assuming running in local environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesfully set kaggle credentials\n"
     ]
    }
   ],
   "source": [
    "if colab_flag == True:\n",
    "  import json\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "\n",
    "  # Set the file path\n",
    "  file_path = '/content/drive/MyDrive/dtu/fastAI/04_NLP/kaggle_api.json'\n",
    "\n",
    "  # Check if the file exists\n",
    "  if os.path.exists(file_path):\n",
    "      # Load the JSON file\n",
    "      with open(file_path) as f:\n",
    "          creds = json.load(f)\n",
    "      print('Sucesfully set kaggle credentials')\n",
    "  else:\n",
    "      # Handle the case when the file does not exist\n",
    "      creds = None  # or any other appropriate action you want to take\n",
    "      print('Error: File not found, Credentials NOT set')\n",
    "else:\n",
    "    import json\n",
    "    file_path = \"../secrets/kaggle_api.json\"\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the JSON file\n",
    "        with open(file_path) as f:\n",
    "            creds = json.load(f)\n",
    "        print('Sucesfully set kaggle credentials')\n",
    "    else:\n",
    "        # Handle the case when the file does not exist\n",
    "        creds = None  # or any other appropriate action you want to take\n",
    "        print('Error: File not found, Credentials NOT set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder exists\n",
      "gender_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "#using `pathlib.Path to work with paths in Python`\n",
    "from pathlib import Path\n",
    "#Set path for the titanic dataset\n",
    "path = Path('titanic')\n",
    "\n",
    "if path.exists():\n",
    "  print('Data folder exists')\n",
    "else:\n",
    "  print('Data not detected, starting download')\n",
    "  #Setup of kaggle credentials to use the API for downloading dataset\n",
    "  cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
    "  if not cred_path.exists():\n",
    "    cred_path.parent.mkdir(exist_ok=True)\n",
    "    cred_path.write_text(json.dumps(creds))\n",
    "    #If not Json\n",
    "    #cred_path.write_text(creds)\n",
    "    cred_path.chmod(0o600)\n",
    "  import zipfile,kaggle\n",
    "  #Download data\n",
    "  kaggle.api.competition_download_cli(str(path))\n",
    "  #Unzip at path\n",
    "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
    "\n",
    "#Verifying the the local content\n",
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recomended tweaks for display settings \n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                                 Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0            1         0       3                              Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1      0          PC 17599   \n",
       "2            3         1       3                               Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3            4         1       1         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4            5         0       3                             Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "\n",
       "      Fare Cabin Embarked  \n",
       "0   7.2500   NaN        S  \n",
       "1  71.2833   C85        C  \n",
       "2   7.9250   NaN        S  \n",
       "3  53.1000  C123        S  \n",
       "4   8.0500   NaN        S  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to replace NaN values is simply to set it to the most common value, the Mode. Mode returns the most common value, but if there are 2 or more equally common values, it will return a list of these values - therefore we use iloc[0] to grab only the first element of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fill all NaN values with the mode of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick description of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specifying include = np.number filters the DF to only display columns that have numeric data types\n",
    "df.describe(include=(np.number))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can  be seen that some columns such as fare has a very high max compared to the mean of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a so called long-tail distribution and is often seen in relation to income, where a few people have a very high income, and the majority has a lower income. This might scew the model, and a common way to deal with this is to take the log of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Logfare'] = np.log(df['Fare']+1)\n",
    "#Adding 1 to the fare to avoid log(0) error\n",
    "df['Logfare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising a few of the columns\n",
    "df['Age'].hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that especially the age column and fare have relatively high values to the remainder of the data, we will normalize the relevant dater later on once we have selected the features we want to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the non-numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can't input strings to our numerical, linear model, we will instead encode the non numeric values as dummy variables (also called one-hot encoding). This means that we create a new column for each unique value in the column, and set the value to 1 if the row has that value, and 0 otherwise. We will leave out the columns name, cabin and ticket, since these have too many unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Logfare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                                 Name   Age  SibSp  Parch            Ticket     Fare    Cabin  \\\n",
       "0            1         0                              Braund, Mr. Owen Harris  22.0      1      0         A/5 21171   7.2500  B96 B98   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  38.0      1      0          PC 17599  71.2833      C85   \n",
       "2            3         1                               Heikkinen, Miss. Laina  26.0      0      0  STON/O2. 3101282   7.9250  B96 B98   \n",
       "3            4         1         Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0            113803  53.1000     C123   \n",
       "4            5         0                             Allen, Mr. William Henry  35.0      0      0            373450   8.0500  B96 B98   \n",
       "\n",
       "    Logfare  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "0  2.110213         0.0       1.0         0.0         0.0         1.0       0.0       0.0       1.0  \n",
       "1  4.280593         1.0       0.0         1.0         0.0         0.0       1.0       0.0       0.0  \n",
       "2  2.188856         1.0       0.0         0.0         0.0         1.0       0.0       0.0       1.0  \n",
       "3  3.990834         1.0       0.0         0.0         0.0         1.0       1.0       0.0       0.0  \n",
       "4  2.202765         0.0       1.0         0.0         0.0         1.0       0.0       0.0       1.0  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_dummies will automatically create dummies and remove the original columns\n",
    "#Drop first is optional but will remove the first dummy column to avoid multicollinearity, i.e. the first dummy column can be inferred from the others\n",
    "#However dropping the column require that one adds a constant to the model\n",
    "\n",
    "#dtype to set dummy variables to float, default is true/false\n",
    "df = pd.get_dummies(df,columns=[\"Sex\",\"Embarked\",\"Pclass\"], dtype=np.float64) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Logfare', 'Sex_female', 'Sex_male',\n",
       "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dependent (target) and independent (predictors/features) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df['Survived'].values, dtype=torch.float)\n",
    "print(t_dep.shape)\n",
    "t_dep[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "891 samples with a 0 (dead) or 1 (survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = ['Age', 'SibSp', 'Parch', 'Logfare', 'Sex_male','Sex_female',  \n",
    "                   'Pclass_1', 'Pclass_2', 'Pclass_3','Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "t_indep = tensor(df[feature_columns].values, dtype=torch.float)\n",
    "print(t_indep.shape)\n",
    "t_indep[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "891 samples each with 12 features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a linear model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up coefficients for each columns, starting out with a random number in the range of -0.5 to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "#Setting the number of coefficients to second element in the shape of the independent tensor, i.e. 12\n",
    "n_coeff = t_indep.shape[1]\n",
    "#rand returns a tensor with random values between 0 and 1\n",
    "#We subtract 0.5 to get a mean of 0\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing the data**\n",
    "By dividing each value with the max value of the column, we normalize the data to be between 0 and 1. This is done to avoid the model being scewed by the large values of the fare and age columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim. \n",
    "#And indices is the index location of each maximum value found (argmax).\n",
    "\n",
    "#dim=0 means that we are looking for the maximum value in each column\n",
    "vals, indicies = t_indep.max(dim=0)\n",
    "t_indep = t_indep/vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting**\n",
    "The asterix * denotes element wise matrix multiplication, which require the two matrices to have the same shape. However, we can use broadcasting to multiply a matrix with a vector, where the vector is applied to each row of the matrix. This is very useful in machine learning, where we often have a matrix of features, and a vector of coefficients.\n",
    "\n",
    "By conducting element wise multiplication of the coefficients and the normalized features, and summing the result, we get a simple prediction for each row (i.e. per data sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n",
    "print(preds.shape)\n",
    "preds[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "To do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds - t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps):\n",
    "    return (indeps*coeffs).sum(axis=1)\n",
    "\n",
    "def calc_loss(coeffs,indeps,deps):\n",
    "    preds = calc_preds(coeffs,indeps)\n",
    "    return torch.abs(preds-deps).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent step\n",
    "In this section, we're going to do a single \"epoch\" of gradient descent manually. The only thing we're going to automate is calculating gradients.\n",
    "\n",
    "To get PyTorch to calculate gradients, we'll need to call requires_grad_() on our coeffs (if you're not sure why, review the previous notebook, How does a neural net really work?, before continuing):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs,t_indep,t_dep)\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use backward() to ask PyTorch to calculate gradients now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **each time we call backward, the gradients are actually added to whatever is in the .grad attribute**. Let's try running the above steps again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, our .grad values are have doubled. That's because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero. We can do this with the .zero_() method:\n",
    "## REMEMBER to set grad to zero after each epoch\n",
    "\n",
    "We can now do one gradient descent step, and check that our loss decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4945)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    coeffs.sub_(0.1 * coeffs.grad)\n",
    "    coeffs.grad.zero_()\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that a.sub_(b) subtracts b from a in-place**. In PyTorch, any method that ends in _ changes its object in-place. Similarly, a.zero_() sets all elements of a tensor to zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the linear model\n",
    "First we need to split our dataset into a training and validation set.\n",
    "\n",
    "For this script we will use the fastAI library to do the splitting, which returns the indicies to split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split, val_split = RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep, val_indep = t_indep[trn_split], t_indep[val_split]\n",
    "trn_dep, val_dep = t_dep[trn_split], t_dep[val_split]\n",
    "len(trn_indep), len(val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then creating 3 functions to \n",
    "- initialize the coefficients\n",
    "- one epoch to calculate the gradients \n",
    "- update the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    return (torch.rand(n_coeff)-0.5).requires_grad_()\n",
    "\n",
    "def update_coeffs(coeffs,lr):\n",
    "    coeffs.sub_(coeffs.grad*lr)\n",
    "    coeffs.grad.zero_()\n",
    "\n",
    "def one_epoch(coeffs,lr):\n",
    "    loss = calc_loss(coeffs, trn_indep,trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        update_coeffs(coeffs,lr)\n",
    "        print(f\"{loss:.3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs):\n",
    "        one_epoch(coeffs,lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(18, lr=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss decreases as expected - training works!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intepreting the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.2694),\n",
       " 'SibSp': tensor(0.0901),\n",
       " 'Parch': tensor(0.2359),\n",
       " 'Logfare': tensor(0.0280),\n",
       " 'Sex_male': tensor(-0.3990),\n",
       " 'Sex_female': tensor(0.2345),\n",
       " 'Pclass_1': tensor(0.7232),\n",
       " 'Pclass_2': tensor(0.4112),\n",
       " 'Pclass_3': tensor(0.3601),\n",
       " 'Embarked_C': tensor(0.0955),\n",
       " 'Embarked_Q': tensor(0.2395),\n",
       " 'Embarked_S': tensor(0.2122)}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(): return dict(zip(feature_columns, coeffs.requires_grad_(False)))\n",
    "show_coeffs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it can be seen that a high age negatively correlates with survival rate (reasonable), and that being a male also negatively correlate with survival rate vs. being a female that positively correlate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy\n",
    "Absolute error is not the metric that kaggle uses to evaluate the model, instead we need to calculate the accuracy of the model. This is done by checking if the prediction is above or below 0.5, and comparing it to the actual value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs,val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume that any passenger with a score of over 0.5 is predicted to survive. So that means we're correct for each row where preds>0.5 is the same as the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool() == (preds>0.5)\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our accuracy overall is:\n",
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs,val_indep):\n",
    "    preds = calc_preds(coeffs,val_indep)\n",
    "    return (val_dep.bool() == (preds>0.5)).float().mean()\n",
    "\n",
    "acc(coeffs, val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid to adjust the output\n",
    "Some predictions are >1 or <0 to fix this we use the sigmoid function to adjust the output to be between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps):\n",
    "    return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510; 0.506; 0.502; 0.497; 0.493; 0.489; 0.485; 0.481; 0.477; 0.472; 0.468; 0.464; 0.460; 0.457; 0.453; 0.449; 0.446; 0.442; "
     ]
    }
   ],
   "source": [
    "#Since train_model rely on calc_loss, that rely on calc_preds (which we just updated) the entire train loop is now changed to include sigmoid on the output \n",
    "\n",
    "#With updated sigmoid in fact performs worse at previous LR, but at higher LR outperforms>\n",
    "coeffs = train_model(18,lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510; 0.328; 0.328; 0.328; 0.327; 0.326; 0.319; 0.264; 0.213; 0.211; 0.205; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(100,lr=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The new accuracy is likewise much better,\n",
    "acc(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-3.1519),\n",
       " 'SibSp': tensor(-1.3649),\n",
       " 'Parch': tensor(-0.2119),\n",
       " 'Logfare': tensor(0.1123),\n",
       " 'Sex_male': tensor(-20.2622),\n",
       " 'Sex_female': tensor(15.4407),\n",
       " 'Pclass_1': tensor(5.9006),\n",
       " 'Pclass_2': tensor(2.1041),\n",
       " 'Pclass_3': tensor(-11.1671),\n",
       " 'Embarked_C': tensor(1.9818),\n",
       " 'Embarked_Q': tensor(2.5129),\n",
       " 'Embarked_S': tensor(-8.6047)}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting to Kaggle\n",
    "\n",
    "First loading the test set to test that our model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out fare has 1 missing value, we will simply fill this with the mean of the column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Null value of fare with mode of the column\n",
    "\n",
    "modes = tst_df.mode().iloc[0]\n",
    "tst_df.fillna(modes, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale fare to log\n",
    "tst_df['Logfare'] = np.log(tst_df['Fare']+1)\n",
    "#Obtain dummy values\n",
    "tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"], dtype=float)\n",
    "\n",
    "tst_indep = tensor(tst_df[feature_columns].values, dtype=torch.float)\n",
    "\n",
    "#Normalize USING THE MAX VALUE OF THE TRAIN SET (vals). Important.\n",
    "tst_indep = tst_indep / vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note form Jeremy:\n",
    "Any preprocessing you do on the training set, such as normalisation, should use the exact same values (not just the same process) on the validation/test sets (and in production).\n",
    "\n",
    "The sample submission on the Kaggle competition site shows that we're expected to upload a CSV with just PassengerId and Survived, so let's create that and save it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(coeffs,tst_indep)>0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = tst_df[['PassengerId','Survived']]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,1\n",
      "899,0\n",
      "900,1\n"
     ]
    }
   ],
   "source": [
    "sub_df.to_csv('sub.csv', index=False)\n",
    "\n",
    "#Linux command to print the first lines of the sub.csv file\n",
    "!head sub.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using matrix multiplication\n",
    "Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the @ operator to indicate matrix products, and is supported by PyTorch tensors. \n",
    "\n",
    "**Matrix vector product is more efficient than element wise multiplication and summing**\n",
    "\n",
    "Therefore, we can replicate the above calculate more simply like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19.1587, -29.8230, -30.3552, -27.3944, -27.7003, -28.2174,   6.1104,   7.8844, -40.9275,   5.1605, -41.2554, -30.5489, -40.3526,\n",
       "          5.8802, -41.3374, -24.6796, -25.4676,   7.9791, -28.2401,  -5.5117, -40.9403, -25.1130,  21.6654,   6.8830, -40.7845, -29.9746,\n",
       "         -4.5316, -25.3494, -40.6630,   5.8799,   8.2077,  -5.8156, -40.7433, -41.1961,  18.9223,  -5.1005, -24.7541,  22.4540, -40.9400,\n",
       "         -5.4474, -27.4674, -40.9400, -28.2122,  22.1405, -40.7824,  -6.0564, -40.9855, -40.9526, -29.8247,  -5.1600, -13.8423, -41.2427,\n",
       "        -41.0791, -40.9815, -27.7432, -27.9796, -29.8230, -41.5725, -40.8218, -41.1058, -13.5014, -40.8369, -26.0565, -40.8220,   7.0952,\n",
       "        -23.7506, -27.6609, -41.5126, -30.6479,   7.2152, -41.0191,   5.2893, -27.9402, -40.9373, -23.8527, -40.6253, -40.9400, -24.5529,\n",
       "        -27.4639, -28.5647, -27.1124,  22.1841, -40.9009, -40.9416,   7.0140, -17.3350, -13.1751,  12.0300,  18.3107, -27.6215, -41.2546,\n",
       "        -40.9400,  22.2252, -30.5916,   5.9034, -17.5473, -28.5159,   5.5570,   5.9587, -29.6281, -40.9099,   5.8799, -41.2555, -41.1767,\n",
       "        -24.2853, -28.3701, -41.1737,   7.2245, -13.4540, -41.3097,   7.6286,  -5.6702, -23.8501,  22.4645, -40.9400,  20.8665,  -6.4347,\n",
       "        -29.8230, -41.6500,  21.4170, -41.3155, -14.8708, -29.8230,  -5.2186, -30.3552, -24.0471,  -5.2771,  -5.3163, -40.6221, -28.6077,\n",
       "         12.1866, -41.0991,   7.4104,   7.7071,  22.2967, -40.7430, -29.0392, -41.1343, -17.5655,   7.6167, -27.8973,  21.1824, -41.7696,\n",
       "        -30.1382,  -5.7649,  10.1624, -41.4904,   5.2958,  12.1374,   4.4963,  -5.3286,   5.8093,   8.1566, -29.8881, -30.1458, -42.3385,\n",
       "        -40.9400,  -5.2469, -28.0549, -40.9303,  22.4480, -17.4291, -41.0955, -24.5397,  21.7323,  11.1035,   7.8109,   7.3328, -25.6994,\n",
       "        -25.0712,  -4.9319, -40.7333,  11.7750, -40.9373, -41.7282,  11.3245, -23.8498, -40.5437])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19.1587, -29.8230, -30.3552, -27.3944, -27.7003, -28.2174,   6.1104,   7.8844, -40.9275,   5.1605, -41.2554, -30.5489, -40.3526,\n",
       "          5.8802, -41.3374, -24.6796, -25.4676,   7.9791, -28.2401,  -5.5117, -40.9403, -25.1130,  21.6654,   6.8830, -40.7845, -29.9746,\n",
       "         -4.5316, -25.3494, -40.6630,   5.8799,   8.2077,  -5.8156, -40.7433, -41.1961,  18.9223,  -5.1005, -24.7541,  22.4540, -40.9400,\n",
       "         -5.4474, -27.4674, -40.9400, -28.2122,  22.1405, -40.7824,  -6.0564, -40.9855, -40.9526, -29.8247,  -5.1600, -13.8423, -41.2427,\n",
       "        -41.0791, -40.9815, -27.7432, -27.9796, -29.8230, -41.5725, -40.8218, -41.1058, -13.5014, -40.8369, -26.0565, -40.8220,   7.0952,\n",
       "        -23.7506, -27.6609, -41.5126, -30.6479,   7.2152, -41.0191,   5.2893, -27.9402, -40.9373, -23.8527, -40.6253, -40.9400, -24.5530,\n",
       "        -27.4639, -28.5647, -27.1124,  22.1841, -40.9009, -40.9416,   7.0140, -17.3350, -13.1751,  12.0300,  18.3107, -27.6215, -41.2546,\n",
       "        -40.9400,  22.2252, -30.5916,   5.9034, -17.5473, -28.5159,   5.5570,   5.9587, -29.6281, -40.9099,   5.8799, -41.2555, -41.1767,\n",
       "        -24.2853, -28.3701, -41.1737,   7.2245, -13.4540, -41.3097,   7.6286,  -5.6702, -23.8501,  22.4645, -40.9400,  20.8665,  -6.4347,\n",
       "        -29.8230, -41.6500,  21.4170, -41.3155, -14.8708, -29.8230,  -5.2186, -30.3552, -24.0471,  -5.2771,  -5.3163, -40.6221, -28.6077,\n",
       "         12.1866, -41.0991,   7.4104,   7.7071,  22.2967, -40.7430, -29.0392, -41.1343, -17.5655,   7.6167, -27.8973,  21.1824, -41.7696,\n",
       "        -30.1382,  -5.7649,  10.1624, -41.4904,   5.2958,  12.1374,   4.4963,  -5.3286,   5.8093,   8.1566, -29.8881, -30.1458, -42.3385,\n",
       "        -40.9400,  -5.2469, -28.0549, -40.9303,  22.4480, -17.4291, -41.0955, -24.5397,  21.7323,  11.1035,   7.8109,   7.3328, -25.6994,\n",
       "        -25.0712,  -4.9319, -40.7333,  11.7750, -40.9373, -41.7282,  11.3245, -23.8498, -40.5437])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps):\n",
    "    return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in order to do matrix products, we need to turn coeffs into a column vector either by using .unsqueeze(-1) or by a 1 in the shape argument when initializing the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    return (torch.randn(n_coeff,1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([713]), torch.Size([178]))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dep.shape, val_dep.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to turn the dependent variable into a column vector which can be done by using .unsqueeze(1) or by indexin the column dimension with the value None (i.e. y = y[:,None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([713, 1]), torch.Size([178, 1]))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dep = trn_dep[:,None]\n",
    "\n",
    "val_dep = val_dep.unsqueeze(1)\n",
    "\n",
    "trn_dep.shape, val_dep.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can now be trained, more efficiently, but with similar output as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481; 0.324; 0.299; 0.208; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(30,lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs, val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single hidden layer\n",
    "Needs n_coefficients as inputs, and n_hidden as outputs\n",
    "Second layer needs n_hidden as inputs and 1 as output (and a constant term added)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    #Divide by n_hidden found by fiddling and the need to scale coefficients relative to number of layers ish\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden) - 0.5)/n_hidden\n",
    "    #0.3 found by fiddling to obtain convergence\n",
    "    layer2 = torch.rand(n_hidden,1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create predictions we need to do matrix multiplication of the input with the first layer, after which the output is passed through a ReLU function, and then the output is again matrix multiplied with the second layer finally with a sigmoid function to get the output between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because we need the relu function and the sigmoid function\n",
    "import torch.nn.functional as F \n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    result = F.relu(indeps@l1)\n",
    "    result = result@l2 + const\n",
    "    return F.sigmoid(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With several set of coefficients we need to add a loop to update each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs,lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad*lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.532; 0.520; 0.505; 0.487; 0.466; 0.439; 0.407; 0.373; 0.343; 0.319; 0.301; 0.286; 0.274; 0.264; 0.256; 0.250; 0.245; 0.240; 0.237; 0.234; 0.231; 0.229; 0.227; 0.226; 0.224; 0.223; 0.222; 0.221; 0.220; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(30, lr=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.400; 0.260; 0.390; 0.221; 0.211; 0.197; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs, val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar accuracy as the simple linear model, likely the dataset is simply not complex enough to need a NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural network\n",
    "Adding aditional hidden layers (prev had 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    #Size of hidden layers (i.e. 2 layers of 10) --> a list of 2 elements: [2]\n",
    "    hidden = [10,10]\n",
    "    #A list of all layer sizes (i.e. [12,10,10,1] ) --> a list of 4 elements [4]\n",
    "    sizes = [n_coeff] + hidden + [1]\n",
    "    # Num of layers (i.e. 4)\n",
    "    n = len(sizes)\n",
    "    #Initalize a list of coefficient matrixes w dimensions according to the Sizes list \n",
    "    # i.e. [tensor[12,10], tensor[10,10], tenspr[10,1]] --> a list of 3 tensors [3]\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    #initalize constants for the 3 coefficient layers as tensors (i.e. [tensor[1],tensor[1],tensor[3]] ) --> a list of 3 tensors [3]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    #Loop over each tensor and set requires_grad_ true \n",
    "    for l in layers+consts: \n",
    "        l.requires_grad_()\n",
    "    return layers,consts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days -- it's very finicky to get a good starting point for our coefficients. Nowadays, we have ways to deal with that, which we'll learn about in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    result = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        result = result@l + consts[i]\n",
    "        if i != n-1:\n",
    "            result = F.relu(result)\n",
    "    return torch.sigmoid(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs,lr):\n",
    "    layers, consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad*lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521; 0.483; 0.427; 0.379; 0.379; 0.379; 0.379; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.377; 0.376; 0.371; 0.333; 0.239; 0.224; 0.208; 0.204; 0.203; 0.203; 0.207; 0.197; 0.196; 0.195; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(30, lr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs, val_indep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, achieving sucesfull training and similar performance to that of the linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
